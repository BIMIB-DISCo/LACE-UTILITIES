library("devtools")
document()
library("devtools")
document()
# Main function for phylogeny reconstruction with longitudinal data#
learn.longitudinal.phylogeny <- function( D, lik_w = rep(1/length(D),length(D)), alpha = 10^-3, beta = 10^-2, initialization = NULL, num_rs = 50, num_iter = 10000, n_try_bs = 500, learning_rate = 1, marginalize = FALSE, seed = NULL, verbose = TRUE ) {#
    # Set the seed#
    set.seed(seed)#
#
    # Do we have datasets with different error rates?#
    different.error.rates <- FALSE#
    if(length(alpha)>1) {#
        different.error.rates <- TRUE#
    }#
    # Initialize global result variables (best solution among all restarts)#
    B_global <- NULL#
    C_global <- NULL#
    lik_global <- NULL#
    joint_lik_global <- NULL#
    # First of all, we remove any NA value from data#
    for(i in 1:length(D)) {#
        if(any(is.na(D[[i]]))) {#
            D[[i]][which(is.na(D[[i]]),arr.ind=TRUE)] <- -3#
        }#
    }#
    # Repeat for num_rs number of restarts#
    for(i in 1:num_rs) {#
        if(verbose) {#
            cat(paste0("Performing restart number ",as.character(as.integer(i))," out of ",as.character(as.integer(num_rs))), "\n")#
        }#
        # Initialize B#
        if(i==1) {#
            if(is.null(initialization)) {#
                B <- initialize.B(D,seed=round(runif(1)*10000))#
            }#
            else {#
                B <- initialization#
            }#
        }#
        else {#
            # Random relabeling of all clones#
            B <- B_global#
            colnames(B) <- c('r',sample(1:(ncol(B)-1)))#
        }#
        res <- compute.C(B,D,lik_w,alpha,beta,different.error.rates,marginalize)#
        C <- res$C#
        lik <- res$lik#
        joint_lik <- res$joint_lik#
        # Initialize result variables (best solution for the current restart)#
        B_best <- B#
        C_best <- C#
        lik_best <- lik#
        joint_lik_best <- joint_lik#
        count_lik_best_cons <- 0#
        # Repeat until num_iter number of iterations is reached#
        for(j in 1:num_iter) {#
            if(verbose && (j %% 100)==0) {#
                cat(paste0("Performed iteration number ",as.character(as.integer(j))," out of ",as.character(as.integer(num_iter))," | Current best log likelihood ",joint_lik_best,"\n"))#
            }#
            # Try move on B#
            B_tmp <- move.B(B,seed=round(runif(1)*10000))#
            # Compute C at maximun likelihood given B_tmp and returns its likelihood#
            res <- compute.C(B_tmp,D,lik_w,alpha,beta,different.error.rates,marginalize)#
            C_tmp <- res$C#
            lik_tmp <- res$lik#
            joint_lik_tmp <- res$joint_lik#
            # If likelihood at current step is better than best likelihood, replace best model with current#
            if(joint_lik_tmp > joint_lik_best) {#
                B_best <- B_tmp#
                C_best <- C_tmp#
                lik_best <- lik_tmp#
                joint_lik_best <- joint_lik_tmp#
                count_lik_best_cons <- 0#
                B <- B_tmp#
                C <- C_tmp#
                lik <- lik_tmp#
                joint_lik <- joint_lik_tmp#
            }#
            else {#
                count_lik_best_cons <- count_lik_best_cons + 1#
                if(count_lik_best_cons > n_try_bs) {#
                    # Warning message#
                    if(verbose) {#
                        cat(paste0("Not improving likelihood of best solution after ",as.character(as.integer(n_try_bs)), " iterations. Skipping to next restart.\n"))#
                    }#
                    break#
                }#
                # Take the current state with a probability proportional to the ratio of the two likelihoods#
                rho <- min(exp(((joint_lik_tmp-joint_lik)/learning_rate)),1)#
                if(runif(1)<=rho) {#
                    B <- B_tmp#
                    C <- C_tmp#
                    lik <- lik_tmp#
                    joint_lik <- joint_lik_tmp#
                }#
            }#
        }#
        if(is.null(joint_lik_global) || (joint_lik_best>joint_lik_global)) {#
            B_global <- B_best#
            C_global <- C_best#
            lik_global <- lik_best#
            joint_lik_global <- joint_lik_best#
        }#
    }#
    return(list(B=B_global,C=C_global,lik=lik_global,joint_lik=joint_lik_global))#
}#
#
# Initialize B#
initialize.B <- function( D, seed = NULL ) {#
    # Define number of mutations#
    m <- ncol(D[[1]])#
    # Initialize B#
    B <- array(0,c((m+1),(m+1)))#
    rownames(B) <- c('r',1:m)#
    colnames(B) <- c('r',sample(1:m))#
    diag(B) <- 1#
    B[,1] <- 1#
    # Add arcs with probability 50%#
    p <- 0.50#
    for(i in 2:(nrow(B)-1)) {#
        if(runif(1)<p) {#
            B[(i+1),] <- B[i,] + B[(i+1),]#
        }#
    }#
    B[which(B>1)] <- 1#
    return(B)#
}#
#
# Performing either relabeling or edge changing moves on B#
move.B <- function( B, seed = NULL ) {#
    # Random probability of choosing a move#
    p <- runif(1)#
    # Perform pairwise relabeling with 55% probability#
    if(p<0.55) {#
        # Relabeling#
        chosen <- sample(2:ncol(B),2,replace=FALSE)#
        tmp <- colnames(B)[chosen[1]]#
        colnames(B)[chosen[1]] <- colnames(B)[chosen[2]]#
        colnames(B)[chosen[2]] <- tmp#
    }#
    # Perform structural moves with 40% probability#
    else if(p>=0.55&&p<0.95) {#
        # Change one arch#
        is_not_valid <- TRUE#
        while(is_not_valid) {#
            ch_1 <- sample(3:nrow(B),1)#
            ch_2 <- sample(1:(ch_1-1),1)#
            # A pair of two nodes is valid if the nodes are not already directly connected#
            if(!(all(B[ch_1,1:ch_2]==B[ch_2,1:ch_2])&&sum(B[ch_1,])==(sum(B[ch_2,])+1))) {#
                is_not_valid <- FALSE#
            }#
        }#
        # Performing move on ch_1#
        ch_1_bkp <- B[ch_1,1:ch_1]#
        B[ch_1,1:(ch_1-1)] <- c(1,rep(0,(ch_1-2)))#
        B[ch_1,] <- B[ch_1,] + B[ch_2,]#
        # Performing move on children of ch_1#
        if(ch_1 != nrow(B)) {#
            for(i in (ch_1+1):nrow(B)) {#
                if(all(ch_1_bkp==B[i,1:ch_1])) {#
                    B[i,1:(ch_1-1)] <- c(1,rep(0,(ch_1-2)))#
                    B[i,] <- B[i,] + B[ch_2,]#
                }#
            }#
        }#
        B[which(B>1)] <- 1#
    }#
    # Perform full relabeling with 5% probability#
    else if(p>=0.95) {#
        # Random relabeling of all clones#
        colnames(B) <- c('r',sample(1:(ncol(B)-1)))#
    }#
    return(B)#
#
}#
#
# Compute attachments matrix C at maximum likelihood given B, D and P#
compute.C <- function( B, D, lik_w = rep(1/length(D),length(D)), alpha = 10^-3, beta = 10^-2, different.error.rates = FALSE, marginalize = FALSE ) {#
    # Initialize return variables#
    C_res <- list()#
    lik_matrix_res <- list()#
    lik_res <- NULL#
    joint_lik_res <- 0.0#
    # Determine indeces to order D such that it matches B#
    idx_srt <- as.integer(colnames(B)[2:ncol(B)])#
    # For each time point#
    curr_alpha <- alpha#
    curr_beta <- beta#
    for(i in 1:length(D)) {#
#
        if(different.error.rates) {#
            curr_alpha <- alpha[i]#
            curr_beta <- beta[i]#
        }#
        # Initialize C for the current time point#
        lik_time <- 0#
        # Go through all the cells#
        curr_cells_D <- D[[i]][,idx_srt,drop=FALSE]#
        # Find assignment at maximum log likelihood for current cell#
        lik_matrix <- array(0,c(nrow(D[[i]]),(ncol(B)-1)))#
        for(k in 2:nrow(B)) {#
            curr_clone_C = matrix(rep(0,(nrow(B)-1)),nrow=1)#
            curr_clone_C[1,(k-1)] <- 1#
            # Save mapping between ordering in B and dataset D#
            # Factorization D = C dot B. r_D_tilde represents a combination of mutations and clones#
            r_D_tilde <- (curr_clone_C %*% B[-1,-1,drop=FALSE])*2#
            sum_cell_clone <- as.matrix(sweep(curr_cells_D,MARGIN=2,r_D_tilde,"+"))#
            lik_matrix[,(k-1)] <- (curr_beta^rowSums(sum_cell_clone==2)) * ((1-curr_beta)^rowSums(sum_cell_clone==0)) * ((curr_alpha)^rowSums(sum_cell_clone==1)) * ((1-curr_alpha)^rowSums(sum_cell_clone==3))#
        }#
        C_list_time <- rowMaxs(lik_matrix,value=FALSE)#
        if(marginalize==TRUE) {#
            lik_time <- sum(log(rowMeans(lik_matrix)))#
        }#
        else {#
            lik_time <- sum(log(rowMaxs(lik_matrix,value=TRUE)))#
        }#
        C_res[[i]] <- C_list_time#
        lik_matrix_res[[i]] <- lik_matrix#
        lik_res <- c(lik_res,lik_time)#
        joint_lik_res <- joint_lik_res + (lik_time * lik_w[i])#
    }#
    return(list(C=C_res,lik=lik_res,joint_lik=joint_lik_res))#
}
#' Perform inference of the maximum likelihood clonal tree from longitudinal data.#
#' @title LACE#
#'#
#' @examples#
#' data(data_HN120Primary)#
#' inference = LACE(D=data_HN120Primary,lik_w=c(0.338,0.329,0.333),alpha=list(c(0.01,0.01,0.02)),beta=list(c(0.01,0.01,0.02)),num_rs=5,num_iter=10,n_try_bs=5,num_processes=NA,seed=12345,verbose=FALSE)#
#'#
#' @param D Mutation data from multiple experiments for a list of driver genes.#
#' @param lik_w Weight for each data point. If not provided, weights to correct for sample sizes are used.#
#' @param alpha False positive error rate provided as list of elements; if a vector of alpha (and beta) is provided, the inference is performed for multiple values and the solution at #
#' maximum-likelihood is returned.#
#' @param beta False negative error rate provided as list of elements; if a vector of beta (and alpha) is provided, the inference is performed for multiple values and the solution at #
#' maximum-likelihood is returned.#
#' @param initialization Starting point of the mcmc; if not provided, a random starting point is used.#
#' @param num_rs Number of restarts during mcmc inference.#
#' @param num_iter Maximum number of mcmc steps to be performed during the inference.#
#' @param n_try_bs Number of steps without change in likelihood of best solution after which to stop the mcmc.#
#' @param learning_rate Parameter to tune the probability of accepting solutions at lower values during mcmc. Value of learning_rate = 1 (default), set a #
#' probability proportional to the difference in likelihood; values of learning_rate greater than 1 inclease the chance of accepting solutions at lower likelihood #
#' during mcmc while values lower than 1 decrease such probability.#
#' @param marginalize Boolean. Shall I marginalize C when computing likelihood?#
#' @param num_processes Number of processes to be used during parallel execution. To execute in single process mode, #
#' this parameter needs to be set to either NA or NULL.#
#' @param seed Seed for reproducibility.#
#' @param verbose Boolean. Shall I print to screen information messages during the execution?#
#' @return A list of 6 elements: B, C, clones_prevalence, relative_likelihoods, joint_likelihood and error_rates. Here, B returns the maximum likelihood longitudinal #
#' clonal tree, C the attachment of cells to clones and clones_prevalence clones' prevalence; relative_likelihoods and joint_likelihood are respectively the likelihood of #
#' the solutions at each individual time points and the joint likelihood. Finally error_rates provides the best values of alpha and beta among the considered ones.#
#' @param log_file log file where to print outputs when using parallel. If parallel execution is disabled, this parameter is ignored.#
#' @export LACE#
#' @import parallel#
#' @import Rfast#
#'#
LACE <- function( D, lik_w = NULL, alpha = NULL, beta = NULL, initialization = NULL, num_rs = 50, num_iter = 10000, n_try_bs = 500, learning_rate = 1, marginalize = FALSE, num_processes = Inf, seed = NULL, verbose = TRUE, log_file = "" ) {#
    # Set the seed#
    set.seed(seed)#
#
    # Initialize weights to compute weighted joint likelihood#
    if(is.null(lik_w)) {#
        total_sample_size <- 0#
        for(i in 1:length(D)) {#
            total_sample_size <- total_sample_size + nrow(D[[i]])#
        }#
        for(i in 1:length(D)) {#
            lik_w <- c(lik_w,(1-(nrow(D[[i]])/total_sample_size)))#
        }#
        lik_w <- lik_w / sum(lik_w)#
    }#
#
    # Initialize error rates alpha and beta#
    if(is.null(alpha)) {#
        alpha = list(rep(0.01,length(D)))#
        beta = list(rep(0.05,length(D)))#
    }#
    if(verbose) {#
        cat(paste0("Starting inference for a total of ",length(alpha)," difference values of alpha and beta.","\n"))#
    }#
#
    # Setting up parallel execution#
    parallel <- NULL#
    close_parallel <- FALSE#
    if(is.null(parallel)&&length(alpha)>1) {#
        if(is.na(num_processes) || is.null(num_processes) || num_processes == 1) {#
            parallel <- NULL#
        }#
        else if(num_processes==Inf) {#
            cores <- as.integer((detectCores()-1))#
            if(cores < 2) {#
                parallel <- NULL#
            }#
            else {#
                num_processes <- min(num_processes,length(alpha))#
                parallel <- makeCluster(num_processes,outfile=log_file)#
                close_parallel <- TRUE#
            }#
        }#
        else {#
            num_processes <- min(num_processes,length(alpha))#
            parallel <- makeCluster(num_processes,outfile=log_file)#
            close_parallel <- TRUE#
        }#
        if(verbose && !is.null(parallel)) {#
            cat("Executing",num_processes,"processes via parallel...","\n")#
        }#
    }#
#
    # Now start the inference#
    if(is.null(parallel)) {#
#
        # Sequential computation#
        inference <- list()#
#
        for(i in 1:length(alpha)) {#
#
            inference[[i]] <- learn.longitudinal.phylogeny( D = D, #
                                                            lik_w = lik_w, #
                                                            alpha = alpha[[i]], #
                                                            beta = beta[[i]], #
                                                            initialization = initialization, #
                                                            num_rs = num_rs, #
                                                            num_iter = num_iter, #
                                                            n_try_bs = n_try_bs, #
                                                            learning_rate = learning_rate, #
                                                            marginalize = marginalize, #
                                                            seed = round(runif(1)*10000), #
                                                            verbose = verbose)#
        }#
#
    }#
    else {#
#
        # Parallel computation#
        res_clusterEvalQ <- clusterEvalQ(parallel,library("cluster"))#
        res_clusterEvalQ <- clusterEvalQ(parallel,library("Rfast"))#
        clusterExport(parallel,varlist=c("D","lik_w","alpha","beta","initialization","num_rs","num_iter","n_try_bs","learning_rate","marginalize","verbose"),envir=environment())#
        clusterExport(parallel,c("learn.longitudinal.phylogeny","initialize.B","move.B","compute.C"),envir=environment())#
        clusterSetRNGStream(parallel,iseed=round(runif(1)*100000))#
        inference <- parLapply(parallel,1:length(alpha),function(x) {#
            if(verbose) {#
                cat('Performing inference for alpha =',paste0(alpha[[x]],collapse=" | "),'and beta =',paste0(beta[[x]],collapse=" | "),'\n')#
            }#
            inference <- learn.longitudinal.phylogeny( D = D, #
                                                       lik_w = lik_w, #
                                                       alpha = alpha[[x]], #
                                                       beta = beta[[x]], #
                                                       initialization = initialization, #
                                                       num_rs = num_rs, #
                                                       num_iter = num_iter, #
                                                       n_try_bs = n_try_bs, #
                                                       learning_rate = learning_rate, #
                                                       marginalize = marginalize, #
                                                       seed = round(runif(1)*10000), #
                                                       verbose = FALSE)#
#
        })#
    }#
    # Close parallel#
    if(close_parallel) {#
        stopCluster(parallel)#
    }#
#
    # Return the solution at maximum likelihood among the inferrend ones#
    lik <- NULL#
    for(i in 1:length(inference)) {#
        lik <- c(lik,inference[[i]][["joint_lik"]])#
    }#
    best <- which(lik==max(lik))[1]#
    error_rates <- list(alpha=alpha[[best]],beta=beta[[best]])#
#
    # Renaming#
    B <- inference[[best]][["B"]]#
    rownames(B) <- c("Root",paste0("Clone_",rownames(B)[2:nrow(B)]))#
    colnames(B) <- c("Root",colnames(D[[1]])[as.numeric(colnames(B)[2:ncol(B)])])#
    C <- inference[[best]][["C"]]#
    names(C) <- paste0("Experiment_",1:length(C))#
    for(i in 1:length(C)) {#
        tmp <- matrix(C[[i]],ncol=1)#
        rownames(tmp) <- rownames(D[[i]])#
        colnames(tmp) <- "Clone"#
        C[[i]] <- tmp#
    }#
    relative_likelihoods <- inference[[best]][["lik"]]#
    names(relative_likelihoods) <- paste0("Experiment_",1:length(relative_likelihoods))#
    joint_likelihood <- inference[[best]][["joint_lik"]]#
#
    # Finally compute clones' prevalence#
    clones_prevalence <- array(NA,c((dim(B)[1]-1),(length(C)+1)))#
    rownames(clones_prevalence) <- rownames(B)[2:nrow(B)]#
    colnames(clones_prevalence) <- c(paste0("Experiment_",1:length(C)),"Total")#
    total_number_cell <- length(unlist(C))#
    for(i in 1:dim(clones_prevalence)[1]) {#
        clone_number_cell <- 0#
        for(j in 1:length(C)) {#
            clone_number_cell <- clone_number_cell + length(which(C[[j]]==i))#
            clones_prevalence[i,j] <- length(which(C[[j]]==i)) / dim(C[[j]])[1]#
        }#
        clones_prevalence[i,"Total"] <- clone_number_cell / total_number_cell#
    }#
#
    return(list(B=B,C=C,clones_prevalence=clones_prevalence,relative_likelihoods=relative_likelihoods,joint_likelihood=joint_likelihood,error_rates=error_rates))#
#
}
load("/Users/daniele/Documents/BIMIB/LACE/data/data_HN137Primary.RData")
lik_weights = c(0.338,0.329,0.333)
alpha = list()#
alpha[[1]] = c(0.01,0.01,0.02)#
alpha[[2]] = c(0.05,0.05,0.10)#
beta = list()#
beta[[1]] = c(0.01,0.01,0.02)#
beta[[2]] = c(0.10,0.10,0.10)
alpha
beta
head(alpha)
inference = LACE(D=data_HN120Primary,lik_w=lik_weights,alpha=alpha,beta=beta,num_rs=5,num_iter=10,n_try_bs=5,num_processes=NA,seed=12345,verbose=FALSE)
ls()
load("/Users/daniele/Documents/BIMIB/LACE/data/data_HN120Primary.RData")
ls()
inference = LACE(D=data_HN120Primary,lik_w=lik_weights,alpha=alpha,beta=beta,num_rs=5,num_iter=10,n_try_bs=5,num_processes=NA,seed=12345,verbose=FALSE)
library(Rfasrt)
library(Rfast)
inference = LACE(D=data_HN120Primary,lik_w=lik_weights,alpha=alpha,beta=beta,num_rs=5,num_iter=10,n_try_bs=5,num_processes=NA,seed=12345,verbose=FALSE)
inference
load("/Users/daniele/Documents/BIMIB/LACE/data/inference_HN120Primary.RData")
names(inference_HN120Primary)
head(names(inference_HN120Primary))
clones_prevalence$clones_prevalence
inference_HN120Primary $clones_prevalence
library("devtools")
document()
library("devtools")
document()
library("devtools")
document()
library("devtools")
document()
library("devtools")
document()
library("devtools")
document()
library(devtools)
document()
load("/Users/daniele/Documents/BIMIB/LACE/data/inference_HN120Metastasis.RData")
load("/Users/daniele/Documents/BIMIB/LACE/data/inference_HN120Primary.RData")
ls()
B = inference_HN120Primary$B
error_rates = inference_HN120Primary$error_rates
error_rates
# Finally compute clones' summary#
    clones_summary <- list()#
    Bwor <- B[,-1]#
    i = 2#
    for(c in rownames(Bwor[-1,])) {#
        mut_list <- colnames(Bwor)[Bwor[i,]==1]#
        clones_summary[[c]] <- mut_list#
        i = i + 1#
    }
clones_summary
inference_HN120Primary$error_rates = NULL
inference_HN120Primary
inference_HN120Primary[["clones_summary"]] = clones_summary
inference_HN120Primary[["error_rates"]] = error_rates
inference_HN120Primary
save(inference_HN120Primary,file="inference_HN120Primary.RData")
ls()
B = inference_HN120Metastasis$B
error_rates = inference_HN120Metastasis$error_rates
inference_HN120Metastasis$error_rates = NULL
# Finally compute clones' summary#
    clones_summary <- list()#
    Bwor <- B[,-1]#
    i = 2#
    for(c in rownames(Bwor[-1,])) {#
        mut_list <- colnames(Bwor)[Bwor[i,]==1]#
        clones_summary[[c]] <- mut_list#
        i = i + 1#
    }
clones_summary
inference_HN120Metastasis[["clones_summary"]] = clones_summary
inference_HN120Metastasis[["error_rates"]] = error_rates
inference_HN120Metastasis
save(inference_HN120Metastasis,file="inference_HN120Metastasis.RData")
library("devtools")
document()
library("devtools")
document()
library("devtools")
document()
library("devtools")
document()
library("devtools")
document()
library("devtools")
document()
document()
